{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3867ed09-0147-416d-af34-d139a255b091",
   "metadata": {},
   "source": [
    "# Training UNet Architecture to Segment Salt Refineries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b708d32-076a-4f9f-966d-072bb23f3e4b",
   "metadata": {},
   "source": [
    "## Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a951f6-33ce-4cca-8938-92b83ace580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configurations.dataset import SegmentationDataset\n",
    "from configurations.model import UNet\n",
    "from configurations import config\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915a7a90-cb6c-404f-95a6-66567d6b118c",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "136eab54-84b6-49c9-99f9-fece77db44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and mask filepaths in a sorted manner\n",
    "imagePaths = sorted(list(paths.list_images(config.IMAGE_DATASET_PATH)))\n",
    "maskPaths = sorted(list(paths.list_images(config.MASK_DATASET_PATH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e2abb-582f-4379-8f1d-5ed00b5ddb10",
   "metadata": {},
   "source": [
    "## Train test spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552f2d59-8758-4600-8742-baf9b1a8e0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving testing image paths...\n"
     ]
    }
   ],
   "source": [
    "# Partition the data into training and testing splits using 85% of\n",
    "# the data for training and the remaining 15% for testing\n",
    "split = train_test_split(imagePaths, maskPaths, test_size=config.TEST_SPLIT, random_state=42)\n",
    "\n",
    "# Unpack the data split\n",
    "(trainImages, testImages) = split[:2]\n",
    "(trainMasks, testMasks) = split[2:]\n",
    "\n",
    "# Write the testing image paths to disk so that we can use then\n",
    "# when evaluating/testing our model\n",
    "print(\"[INFO] saving testing image paths...\")\n",
    "f = open(config.TEST_PATHS, \"w\")\n",
    "f.write(\"\\n\".join(testImages))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe48132-af3a-40e3-99f7-3e62716d8351",
   "metadata": {},
   "source": [
    "## Define transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6f2ec3-7804-4516-b832-5694349ea194",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    " \ttransforms.Resize((config.INPUT_IMAGE_HEIGHT, config.INPUT_IMAGE_WIDTH)),\n",
    "\ttransforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5233c-2e63-4b15-88a4-0f61d44dbaf1",
   "metadata": {},
   "source": [
    "## Create the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eabdce11-a05f-409d-b485-2f709fa83f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] found 3400 examples in the training set...\n",
      "[INFO] found 600 examples in the test set...\n"
     ]
    }
   ],
   "source": [
    "trainDS = SegmentationDataset(imagePaths=trainImages, maskPaths=trainMasks, transforms=transforms)\n",
    "testDS = SegmentationDataset(imagePaths=testImages, maskPaths=testMasks, transforms=transforms)\n",
    "\n",
    "print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n",
    "print(f\"[INFO] found {len(testDS)} examples in the test set...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206657e5-f0cb-4eea-bef3-51d20ed1adf4",
   "metadata": {},
   "source": [
    "## Create the training and test data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83fe7469-3d96-4a94-98c8-56a31588b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(trainDS, shuffle=True,\n",
    "\tbatch_size=config.BATCH_SIZE, pin_memory=config.PIN_MEMORY,\n",
    "\tnum_workers=os.cpu_count())\n",
    "\n",
    "testLoader = DataLoader(testDS, shuffle=False,\n",
    "\tbatch_size=config.BATCH_SIZE, pin_memory=config.PIN_MEMORY,\n",
    "\tnum_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a249c-b58e-4f91-b74a-03681dbf3eb6",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a2b8262-8fd6-4909-93be-5f6837228594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our UNet model\n",
    "unet = UNet().to(config.DEVICE)\n",
    "\n",
    "# Initialize loss function and optimizer\n",
    "lossFunc = BCEWithLogitsLoss()\n",
    "opt = Adam(unet.parameters(), lr=config.INIT_LR)\n",
    "\n",
    "# Calculate steps per epoch for training and test set\n",
    "trainSteps = len(trainDS) // config.BATCH_SIZE\n",
    "testSteps = len(testDS) // config.BATCH_SIZE\n",
    "\n",
    "# Initialize a dictionary to store training history\n",
    "H = {\"train_loss\": [], \"test_loss\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf554151-46bc-4907-8abb-c87b44bde87c",
   "metadata": {},
   "source": [
    "## Training Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898925a-af4d-406f-acbf-d5859f18f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▏                                                                                                                                                                | 1/40 [01:43<1:07:28, 103.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 1/40\n",
      "Train loss: 0.602414, Test loss: 0.6053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████▎                                                                                                                                                            | 2/40 [03:21<1:03:22, 100.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 2/40\n",
      "Train loss: 0.565257, Test loss: 0.5919\n"
     ]
    }
   ],
   "source": [
    "# Loop over epochs\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "for e in tqdm(range(config.NUM_EPOCHS)):\n",
    "\t# set the model in training mode\n",
    "\tunet.train()\n",
    "\n",
    "\t# Initialize the total training and validation loss\n",
    "\ttotalTrainLoss = 0\n",
    "\ttotalTestLoss = 0\n",
    "\n",
    "\t# Loop over the training set\n",
    "\tfor (i, (x, y)) in enumerate(trainLoader):\n",
    "\t\t# send the input to the device\n",
    "\t\t(x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "\n",
    "\t\t# Perform a forward pass and calculate the training loss\n",
    "\t\tpred = unet(x)\n",
    "\t\tloss = lossFunc(pred, y)\n",
    "\n",
    "\t\t# First, zero out any previously accumulated gradients, then\n",
    "\t\t# perform backpropagation, and then update model parameters\n",
    "\t\topt.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\topt.step()\n",
    "\n",
    "\t\t# Add the loss to the total training loss so far\n",
    "\t\ttotalTrainLoss += loss\n",
    "\n",
    "\t# Switch off autograd\n",
    "\twith torch.no_grad():\n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tunet.eval()\n",
    "\n",
    "\t\t# Loop over the validation set\n",
    "\t\tfor (x, y) in testLoader:\n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t(x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "\n",
    "\t\t\t# Make the predictions and calculate the validation loss\n",
    "\t\t\tpred = unet(x)\n",
    "\t\t\ttotalTestLoss += lossFunc(pred, y)\n",
    "\n",
    "\t# Calculate the average training and validation loss\n",
    "\tavgTrainLoss = totalTrainLoss / trainSteps\n",
    "\tavgTestLoss = totalTestLoss / testSteps\n",
    "\n",
    "\t# Update our training history\n",
    "\tH[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "\tH[\"test_loss\"].append(avgTestLoss.cpu().detach().numpy())\n",
    "\n",
    "\t# Print the model training and validation information\n",
    "\tprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, config.NUM_EPOCHS))\n",
    "\tprint(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(\n",
    "\t\tavgTrainLoss, avgTestLoss))\n",
    "\n",
    "# Display the total time needed to perform the training\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "\tendTime - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd762c6-79df-4e92-9b9c-1f1882bb5f6b",
   "metadata": {},
   "source": [
    "## Ploting train graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a16e56-52bf-485c-8f88-c06ec6e320ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(config.PLOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75ef030-a89e-4370-9820-8256fb30bc7d",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9bdfed-e553-4c10-8a4d-092b56139a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the model to disk\n",
    "torch.save(unet, config.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b09fd-af71-4f95-a0b5-2e880753bda0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
